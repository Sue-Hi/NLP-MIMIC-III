{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of Words, Bag of CUIs Approaches:\n",
    "In this notebook I am using bag of words (BoW) and bag of Concept Unique Identifiers (CUIs) that I have extracted using cTAKES to predict 30-day unplanned readmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_adm_notes_clean = pd.read_pickle('Prepared_Data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 51113 entries, 1 to 58975\n",
      "Data columns (total 12 columns):\n",
      "SUBJECT_ID             51113 non-null int64\n",
      "HADM_ID                51113 non-null int64\n",
      "ADMITTIME              51113 non-null datetime64[ns]\n",
      "DISCHTIME              51113 non-null datetime64[ns]\n",
      "DEATHTIME              5792 non-null datetime64[ns]\n",
      "ADMISSION_TYPE         51113 non-null object\n",
      "NEXT_ADMITTIME         11169 non-null datetime64[ns]\n",
      "NEXT_ADMISSION_TYPE    11169 non-null object\n",
      "DAYS_NEXT_ADMIT        11169 non-null float64\n",
      "CATEGORY               49083 non-null object\n",
      "TEXT                   49083 non-null object\n",
      "OUTPUT_LABEL           51113 non-null int64\n",
      "dtypes: datetime64[ns](4), float64(1), int64(3), object(4)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_adm_notes_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I have extracted CUIs of diseases and disorders for each patient using cTAKES and Scala. Here I read this information from a csv file and save it in df_cuis dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuis = pd.read_csv('WithCuis_P.csv', engine = \"c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets see how this dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBJECT_ID_T</th>\n",
       "      <th>HADM_ID_T</th>\n",
       "      <th>CUIS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>145834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>C0021051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>107064</td>\n",
       "      <td>C0022661 C2316810 C0022658 C0012634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>C0406810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>194540</td>\n",
       "      <td>C0020517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUBJECT_ID_T  HADM_ID_T                                 CUIS\n",
       "0             3     145834                                  NaN\n",
       "1             4     185777                             C0021051\n",
       "2             6     107064  C0022661 C2316810 C0022658 C0012634\n",
       "3             9     150750                             C0406810\n",
       "4            11     194540                             C0020517"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cuis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some discharge notes don't have any disease and disorder CUIs. I fill these NaNs with an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuis.fillna(\" \", inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cuis.columns = [\"SUBJECT_ID\", \"HADM_ID\", \"CUIS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging two dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm_notes_clean = pd.merge(df_adm_notes_clean, df_cuis, on = ['SUBJECT_ID','HADM_ID'],how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm_notes_clean = df_adm_notes_clean.sample(n = len(df_adm_notes_clean), random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adm_notes_clean = df_adm_notes_clean.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save 20% of the data for validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = df_adm_notes_clean.sample(frac=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.to_pickle('df_valid.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all=df_adm_notes_clean.drop(df_valid.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As I mentioned in preparation section, data is highly imbalanced. I am going to do down sampling for negative cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_pos = df_train_all.OUTPUT_LABEL == 1\n",
    "df_train_pos = df_train_all.loc[rows_pos]\n",
    "df_train_neg = df_train_all.loc[~rows_pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a balanced dataset (50/50):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train_pos, df_train_neg.sample(n = len(df_train_pos), random_state = 42)],axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling before training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(n = len(df_train), random_state = 42).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle('df_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess for bag-of-words (BoF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # This function preprocesses the text by filling not a number and replacing new lines ('\\n') and carriage returns ('\\r')\n",
    "    df.TEXT = df.TEXT.fillna(' ')\n",
    "    df.TEXT = df.TEXT.str.replace('\\n',' ')\n",
    "    df.TEXT = df.TEXT.str.replace('\\r',' ')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = preprocess_text(df_train)\n",
    "df_valid = preprocess_text(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ssarafrazi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/ssarafrazi/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from numpy import array\n",
    "from scipy.sparse import csr_matrix\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "# keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets look at one of the texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Admission Date:  [**2107-7-19**]     Discharge Date:  [**2107-7-31**]  Date of Birth:   [**2051-5-31**]     Sex:  M  Service:  COLORECTAL SURGERY/GREEN SURGERY  HISTORY OF PRESENT ILLNESS:  This is a 56-year-old man with a history of ulcerative colitis since [**2098**].  The patient was hospitalized almost annually for flareups.  His current flare began three weeks ago at which time he was admitted to [**Hospital3 9683**] for the past three weeks.  He was recently started on IV hydrocortisone and sent home several days prior this admission.  The patient complained of increasing symptoms over the weekend with severe lower abdominal pain with po intake, low grade fevers, nausea, vomiting, and [**6-26**] bloody bowel movements per day.  PAST MEDICAL HISTORY:  Ulcerative colitis.  PAST SURGICAL HISTORY:  None.  MEDICATIONS: 1. Hydrocortisone 100 mg tid. 2. Two Ativan prn. 3. Iron. 4. Folic acid. 5. Prevacid.  ALLERGIES:  6-mercaptopurine, reaction jaundice.  SOCIAL HISTORY:  No tobacco and occasional alcohol.  FAMILY HISTORY:  Mother with [**Name (NI) 4522**] disease.  REVIEW OF SYSTEMS:  No chest pain, shortness of breath, palpitations, no dysuria, hematuria, or hematemesis.  PHYSICAL EXAMINATION ON ADMISSION:  Vital signs:  Temperature at 99.4, heart rate 100, blood pressure 117/86, respirations 16, and pulse oxygenation 98% on room air.  He was alert and oriented times three in no acute distress.  His sclerae were anicteric.  His mucous membranes were moist.  His heart rate was regular, rate, and rhythm with no murmurs, rubs, or gallops.  His lungs were clear to auscultation bilaterally. His abdomen was soft, tender in the lower quadrants to palpation, with no guarding and positive bowel sounds. Rectal examination was grossly heme positive, with positive external hemorrhoid visualized.  His extremities were warm and well perfused with no edema.  A CT scan of the abdomen on admission showed no evidence of free air obstruction or abscess with diffuse colonic thickening and loss of haustral folds and multiple nodular filling defects in the transverse colon.  Please see full report for details.  LABORATORIES ON ADMISSION:  A complete blood count is as follows:  White blood cell count 8.0, hematocrit 33.1, platelet count 201.  White blood cell count differential 90% neutrophils, no band neutrophils, 6.4 lymphocytes, 3.2% monocytes.  Electrolytes as follows:  Sodium 136, potassium 3.9, chloride 100, HCO3 29, BUN 15, creatinine 0.8, glucose of 187.  The patient was admitted to the Colorectal Service under Dr. [**Last Name (STitle) 1888**], and he was written for a diet of nothing by mouth, IV fluids, medicated with IV steroids, antibiotics, and was given a routine preoperative assessment with electrocardiogram and chest x-ray.  On postoperative day two, the patient received a peripherally inserted central catheter line for administration of total parenteral nutrition.  He was started on a morphine sulfate PCA for pain control.  He was visited by the enterostomal nurse therapist for education and discussion of ileostomy care.  On hospital day four, the patient was taken to the operating room for a restorative proctocolectomy, diverting ileostomy. Please see full operative report for details of the procedure.  Following the procedure, the patient was hypotensive with elevated heart rate and decreased urine output.  He was infused with both his Lactated Ringers as well as Hespan for volume resuscitation.  His urine output responded marginally to these boluses.  The patient's postoperative hematocrit and electrolytes were all within normal limits except for a magnesium of 1.3 for which he was given 2 grams of magnesium intravenously.  After several hours of time postoperatively, the patient was noted to have dysnomia and difficulty speaking a Neurology consult was obtained at the time.  Please see full Neurology consult note for details.  A CT scan of the head was obtained with no abnormalities noted.  The patient was transferred to the Surgical Intensive Care Unit team care for monitoring and volume resuscitation on a Neo-Synephrine drip.  On postoperative day one, the patient's blood pressure stabilized, and the patient was taken to MRI for further evaluation of his speech difficulties.  The MRI was suggestive of an acute left temporal infarct with no mass effect or midline shift and no acute occlusion.  Please see full MRI report for details.  The patient was further worked up for cause of the left temporal infarct and on an transesophageal echocardiogram was noted to have a small atrioseptal defect with right to left flow.  Clinically, the patient's aphasia was improving.  His colostomy was viable and putting out small amounts of liquid brown stool.  The patient remained on total parenteral nutrition with consultation from a nutritionist on staff, and the patient was seen by Dr. [**Last Name (STitle) **] for evaluation of closure of the atrioseptal defect.  On hospital day 11, postoperative day six, the patient was deemed stable enough to return to the surgical floor and was transferred from the Intensive Care Unit.  He was able to tolerate regular diet.  His pain was well controlled.  He was able to ambulate and had no further neurological changes or complaints.  On postoperative day eight, he was deemed in stable enough condition to transfer to home with visiting nurse services.  Addendum:  Patient underwent a colonoscopy on hospital day two, which showed severe ulcerations of the colon.  Please see full colonoscopy report for details of procedure.  DISCHARGE DIAGNOSIS: 1. Ulcerative colitis primary status post restorative proctocolectomy with diverting ileostomy. 2. Left temporal lobe cerebral infarct. 3. Atrioseptal defect. 4. Secondary hypotension, hypovolemia.  CONDITION ON DISCHARGE:  Good and stable.  DISCHARGE STATUS:  To home with visiting nurses.  DISCHARGE MEDICATIONS: 1. Aspirin 325 mg tablet one tablet po q day. 2. Clopidogrel 75 mg tablet one tablet po q day. 3. Tylenol #3 30/300 1-2 tablets po q4h as needed for pain. 4. Loperamide 2 mg one capsule po qid. 5. Prednisone 5 mg tablets three tablets po q day x1 week, then two tablets 10 mg po until followup with Dr. [**Last Name (STitle) 1888**]. 6. Pravastatin 20 mg tablet one tablet po q day.  FOLLOW-UP PLANS: 1. Patient is to followup with Dr. [**Last Name (STitle) 1888**] in Colorectal Surgery in [**1-20**] weeks, and has been the office number to call for an appointment. 2. Dr. [**Last Name (STitle) **], Interventional Cardiology for repair of atrioseptal defect.  The patient has been given office number to call for an appointment.  In addition, the patient is referred to Visiting Nurses Association Services for dressing changes, dry gauze twice a day as well as ostomy care routine twice a day.  He is instructed to take a regular diet and regular activity as tolerated.                               [**First Name11 (Name Pattern1) 1112**] [**Last Name (NamePattern4) **], M.D.  Dictated By:[**Last Name (NamePattern1) 5657**]  MEDQUIST36  D:  [**2107-8-8**]  11:17 T:  [**2107-8-16**]  08:12 JOB#:  [**Job Number 51943**] \""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.TEXT[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These texts need lots of cleaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    punc_list = string.punctuation+'0123456789'\n",
    "    t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
    "    text = text.lower().translate(t).split()\n",
    "    \n",
    "    ## Remove stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops and len(w) >= 3]\n",
    "    text = \" \".join(text)\n",
    "    \n",
    "    ## Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    ## Stemming\n",
    "    text = text.split()\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text]\n",
    "    text = \" \".join(stemmed_words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets see how they look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admiss date discharg date date birth sex servic colorect surgeri green surgeri histori present ill year old man histori ulcer coliti sinc patient hospit almost annual flareup current flare began three week ago time admit hospit past three week recent start hydrocortison sent home sever day prior admiss patient complain increas symptom weekend sever lower abdomin pain intak low grade fever nausea vomit bloodi bowel movement per day past medic histori ulcer coliti past surgic histori none medic hydrocortison tid two ativan prn iron folic acid prevacid allergi mercaptopurin reaction jaundic social histori tobacco occasion alcohol famili histori mother name diseas review system chest pain short breath palpit dysuria hematuria hematemesi physic examin admiss vital sign temperatur heart rate blood pressur respir puls oxygen room air alert orient time three acut distress sclera anicter mucous membran moist heart rate regular rate rhythm murmur rub gallop lung clear auscult bilater abdomen soft tender lower quadrant palpat guard posit bowel sound rectal examin grossli heme posit posit extern hemorrhoid visual extrem warm well perfus edema scan abdomen admiss show evid free air obstruct abscess diffus colon thicken loss haustral fold multipl nodular fill defect transvers colon pleas see full report detail laboratori admiss complet blood count follow white blood cell count hematocrit platelet count white blood cell count differenti neutrophil band neutrophil lymphocyt monocyt electrolyt follow sodium potassium chlorid hco bun creatinin glucos patient admit colorect servic last name stitl written diet noth mouth fluid medic steroid antibiot given routin preoper assess electrocardiogram chest ray postop day two patient receiv peripher insert central cathet line administr total parenter nutrit start morphin sulfat pca pain control visit enterostom nurs therapist educ discuss ileostomi care hospit day four patient taken oper room restor proctocolectomi divert ileostomi pleas see full oper report detail procedur follow procedur patient hypotens elev heart rate decreas urin output infus lactat ringer well hespan volum resuscit urin output respond margin bolus patient postop hematocrit electrolyt within normal limit except magnesium given gram magnesium intraven sever hour time postop patient note dysnomia difficulti speak neurolog consult obtain time pleas see full neurolog consult note detail scan head obtain abnorm note patient transfer surgic intens care unit team care monitor volum resuscit neo synephrin drip postop day one patient blood pressur stabil patient taken mri evalu speech difficulti mri suggest acut left tempor infarct mass effect midlin shift acut occlus pleas see full mri report detail patient work caus left tempor infarct transesophag echocardiogram note small atriosept defect right left flow clinic patient aphasia improv colostomi viabl put small amount liquid brown stool patient remain total parenter nutrit consult nutritionist staff patient seen last name stitl evalu closur atriosept defect hospit day postop day six patient deem stabl enough return surgic floor transfer intens care unit abl toler regular diet pain well control abl ambul neurolog chang complaint postop day eight deem stabl enough condit transfer home visit nurs servic addendum patient underw colonoscopi hospit day two show sever ulcer colon pleas see full colonoscopi report detail procedur discharg diagnosi ulcer coliti primari status post restor proctocolectomi divert ileostomi left tempor lobe cerebr infarct atriosept defect secondari hypotens hypovolemia condit discharg good stabl discharg status home visit nurs discharg medic aspirin tablet one tablet day clopidogrel tablet one tablet day tylenol tablet need pain loperamid one capsul qid prednison tablet three tablet day week two tablet followup last name stitl pravastatin tablet one tablet day follow plan patient followup last name stitl colorect surgeri week offic number call appoint last name stitl intervent cardiolog repair atriosept defect patient given offic number call appoint addit patient refer visit nurs associ servic dress chang dri gauz twice day well ostomi care routin twice day instruct take regular diet regular activ toler first name name pattern last name namepattern dictat last name namepattern medquist job job number'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(df_train['TEXT'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks clean and ready for BoW!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TEXT'] = df_train['TEXT'].map(lambda x: clean_text(x))\n",
    "df_valid['TEXT'] = df_valid['TEXT'].map(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I want to add polarized CUIs to texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['TEXT_CUIS']= df_train.TEXT + \" \" + df_train.CUIS\n",
    "df_valid['TEXT_CUIS']= df_valid.TEXT + \" \" + df_valid.CUIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'admiss date discharg date date birth sex servic colorect surgeri green surgeri histori present ill year old man histori ulcer coliti sinc patient hospit almost annual flareup current flare began three week ago time admit hospit past three week recent start hydrocortison sent home sever day prior admiss patient complain increa symptom weekend sever lower abdomin pain intak low grade fever nausea vomit bloodi bowel movement per day past medic histori ulcer coliti past surgic histori none medic hydrocortison tid two ativan prn iron folic acid prevacid allergi mercaptopurin reaction jaundic social histori tobacco occas alcohol famili histori mother name disea review system chest pain short breath palpit dysuria hematuria hematemesi physic examin admiss vital sign temperatur heart rate blood pressur respir pul oxygen room air alert orient time three acut distress sclera anict mucous membran moist heart rate regular rate rhythm murmur rub gallop lung clear auscult bilat abdomen soft tender lower quadrant palpat guard posit bowel sound rectal examin grossli heme posit posit extern hemorrhoid visual extrem warm well perfus edema scan abdomen admiss show evid free air obstruct abscess diffus colon thicken loss haustral fold multipl nodular fill defect transver colon plea see full report detail laboratori admiss complet blood count follow white blood cell count hematocrit platelet count white blood cell count differenti neutrophil band neutrophil lymphocyt monocyt electrolyt follow sodium potassium chlorid hco bun creatinin gluco patient admit colorect servic last name stitl written diet noth mouth fluid medic steroid antibiot given routin preoper assess electrocardiogram chest ray postop day two patient receiv periph insert central cathet line administr total parent nutrit start morphin sulfat pca pain control visit enterostom nur therapist educ discuss ileostomi care hospit day four patient taken oper room restor proctocolectomi divert ileostomi plea see full oper report detail procedur follow procedur patient hypoten elev heart rate decrea urin output infus lactat ringer well hespan volum resuscit urin output respond margin bolus patient postop hematocrit electrolyt within normal limit except magnesium given gram magnesium intraven sever hour time postop patient note dysnomia difficulti speak neurolog consult obtain time plea see full neurolog consult note detail scan head obtain abnorm note patient transfer surgic inten care unit team care monitor volum resuscit neo synephrin drip postop day one patient blood pressur stabil patient taken mri evalu speech difficulti mri suggest acut left tempor infarct mass effect midlin shift acut occlus plea see full mri report detail patient work caus left tempor infarct transesophag echocardiogram note small atriosept defect right left flow clinic patient aphasia improv colostomi viabl put small amount liquid brown stool patient remain total parent nutrit consult nutritionist staff patient seen last name stitl evalu closur atriosept defect hospit day postop day six patient deem stabl enough return surgic floor transfer inten care unit abl toler regular diet pain well control abl ambul neurolog chang complaint postop day eight deem stabl enough condit transfer home visit nur servic addendum patient underw colonoscopi hospit day two show sever ulcer colon plea see full colonoscopi report detail procedur discharg diagnosi ulcer coliti primari status post restor proctocolectomi divert ileostomi left tempor lobe cerebr infarct atriosept defect secondari hypoten hypovolemia condit discharg good stabl discharg status home visit nur discharg medic aspirin tablet one tablet day clopidogrel tablet one tablet day tylenol tablet need pain loperamid one capsul qid prednison tablet three tablet day week two tablet followup last name stitl pravastatin tablet one tablet day follow plan patient followup last name stitl colorect surgeri week offic number call appoint last name stitl interv cardiolog repair atriosept defect patient given offic number call appoint addit patient refer visit nur associ servic dress chang dri gauz twice day well ostomi care routin twice day instruct take regular diet regular activ toler first name name pattern last name namepattern dictat last name namepattern medquist job job number C0009319 C0009324 C0041582'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.TEXT_CUIS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see CUIs are attached to the texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the built in CountVectorizer from scikit-learn package. This vectorizer simply counts how many times each word occurs in the note. There is also a TfidfVectorizer which takes into account how often words are used across all notes, that I use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features = 50000)\n",
    "vect.fit(df_train.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = vect.transform(df_train.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding most frequent words to use them as Stop-Words:Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_words = X_train_tf.sum(axis=0) \n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in     vect.vocabulary_.items()]\n",
    "words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "words_freq_plot = words_freq[:30]\n",
    "values = [value[0] for value in words_freq_plot]\n",
    "freq = [value[1] for value in words_freq_plot]\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (6,8), sharex=True)\n",
    "plt.barh(range(len(values)),freq, align = 'center')\n",
    "plt.yticks(range(len(values)),values)\n",
    "plt.title(\"Top 30 Frequent Words\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Frequncy')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see the most frequent words. Now we can make our own stop words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = ['the','and','to','of','was','with','a','on','in','for','name',\n",
    "                 'is','patient','s','he','at','as','or','one','she','his','her','am',\n",
    "                 'were','you','pt','pm','by','be','had','your','this','date',\n",
    "                 'from','there','an','that','p','are','have','has','h','but','o',\n",
    "                 'namepattern','which','every','also']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making BoW using the TEXT column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['the', 'and', 'to', 'of', 'was', 'with', 'a', 'on', 'in', 'for', 'name', 'is', 'patient', 's', 'he', 'at', 'as', 'or', 'one', 'she', 'his', 'her', 'am', 'were', 'you', 'pt', 'pm', 'by', 'be', 'had', 'your', 'this', 'date', 'from', 'there', 'an', 'that', 'p', 'are', 'have', 'has', 'h', 'but', 'o', 'namepattern', 'which', 'every', 'also'],\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features = 50000,  \n",
    "                       stop_words = my_stop_words)\n",
    "vect.fit(df_train.TEXT.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text_tf = vect.transform(df_train.TEXT.values)\n",
    "X_valid_text_tf = vect.transform(df_valid.TEXT.values)\n",
    "\n",
    "# Response:\n",
    "\n",
    "y_train = df_train.OUTPUT_LABEL\n",
    "y_valid = df_valid.OUTPUT_LABEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Bag of Words (BoW) and Bag of CUIs (BoC) using TEXT_CUIS column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=['the', 'and', 'to', 'of', 'was', 'with', 'a', 'on', 'in', 'for', 'name', 'is', 'patient', 's', 'he', 'at', 'as', 'or', 'one', 'she', 'his', 'her', 'am', 'were', 'you', 'pt', 'pm', 'by', 'be', 'had', 'your', 'this', 'date', 'from', 'there', 'an', 'that', 'p', 'are', 'have', 'has', 'h', 'but', 'o', 'namepattern', 'which', 'every', 'also'],\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features = 50000,  \n",
    "                       stop_words = my_stop_words)\n",
    "                       #ngram_range= (1,3))\n",
    "vect.fit(df_train.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = vect.transform(df_train.TEXT_CUIS.values)\n",
    "X_valid_tf = vect.transform(df_valid.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF using TEXT_CUIS column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=['the', 'and', 'to', 'of', 'was', 'with', 'a', 'on', 'in', 'for', 'name', 'is', 'patient', 's', 'he', 'at', 'as', 'or', 'one', 'she', 'his', 'her', 'am', 'were', 'you', 'pt', 'pm', 'by', 'be', 'had', 'your', 'this', 'date', 'from', 'there', 'an', 'that', 'p', 'are', 'have', 'has', 'h', 'but', 'o', 'namepattern', 'which', 'every', 'also'],\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_TF_IDF = TfidfVectorizer(stop_words = my_stop_words)\n",
    "vect_TF_IDF.fit(df_train.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_IDF = vect_TF_IDF.transform(df_train.TEXT_CUIS.values)\n",
    "X_valid_tf_IDF = vect_TF_IDF.transform(df_valid.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Polarized CUIs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_cui = CountVectorizer(max_features= 5000)\n",
    "vect_cui.fit(df_train.CUIS.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0000768',\n",
       " 'c0000768negp',\n",
       " 'c0000817',\n",
       " 'c0000833',\n",
       " 'c0000924',\n",
       " 'c0000925',\n",
       " 'c0001122',\n",
       " 'c0001125',\n",
       " 'c0001175',\n",
       " 'c0001304',\n",
       " 'c0001339',\n",
       " 'c0001363',\n",
       " 'c0001365',\n",
       " 'c0001418',\n",
       " 'c0001430',\n",
       " 'c0001511',\n",
       " 'c0001623',\n",
       " 'c0001815',\n",
       " 'c0001883',\n",
       " 'c0001969',\n",
       " 'c0001973',\n",
       " 'c0002390',\n",
       " 'c0002395',\n",
       " 'c0002622',\n",
       " 'c0002690',\n",
       " 'c0002694',\n",
       " 'c0002726',\n",
       " 'c0002736',\n",
       " 'c0002792',\n",
       " 'c0002871',\n",
       " 'c0002873',\n",
       " 'c0002878',\n",
       " 'c0002880',\n",
       " 'c0002892',\n",
       " 'c0002893',\n",
       " 'c0002894',\n",
       " 'c0002940',\n",
       " 'c0002940negp',\n",
       " 'c0002963',\n",
       " 'c0002965',\n",
       " 'c0002994',\n",
       " 'c0003123',\n",
       " 'c0003123negp',\n",
       " 'c0003132',\n",
       " 'c0003469',\n",
       " 'c0003486',\n",
       " 'c0003492',\n",
       " 'c0003493',\n",
       " 'c0003504',\n",
       " 'c0003507',\n",
       " 'c0003537',\n",
       " 'c0003578',\n",
       " 'c0003614',\n",
       " 'c0003708',\n",
       " 'c0003803',\n",
       " 'c0003811',\n",
       " 'c0003834',\n",
       " 'c0003855',\n",
       " 'c0003857',\n",
       " 'c0003860',\n",
       " 'c0003864',\n",
       " 'c0003873',\n",
       " 'c0003874',\n",
       " 'c0003949',\n",
       " 'c0004063',\n",
       " 'c0004096',\n",
       " 'c0004096negp',\n",
       " 'c0004114',\n",
       " 'c0004144',\n",
       " 'c0004238',\n",
       " 'c0004238negp',\n",
       " 'c0004239',\n",
       " 'c0004245',\n",
       " 'c0004610',\n",
       " 'c0004763',\n",
       " 'c0005001',\n",
       " 'c0005001negp',\n",
       " 'c0005411',\n",
       " 'c0005586',\n",
       " 'c0005658',\n",
       " 'c0005684',\n",
       " 'c0005695',\n",
       " 'c0005745',\n",
       " 'c0005758',\n",
       " 'c0005779',\n",
       " 'c0006112',\n",
       " 'c0006118',\n",
       " 'c0006142',\n",
       " 'c0006266',\n",
       " 'c0006267',\n",
       " 'c0006277',\n",
       " 'c0006413',\n",
       " 'c0006434',\n",
       " 'c0006826',\n",
       " 'c0007095',\n",
       " 'c0007097',\n",
       " 'c0007102',\n",
       " 'c0007107',\n",
       " 'c0007113',\n",
       " 'c0007114',\n",
       " 'c0007115',\n",
       " 'c0007117',\n",
       " 'c0007131',\n",
       " 'c0007134',\n",
       " 'c0007137',\n",
       " 'c0007137negp',\n",
       " 'c0007138',\n",
       " 'c0007140',\n",
       " 'c0007177',\n",
       " 'c0007193',\n",
       " 'c0007194',\n",
       " 'c0007222negp',\n",
       " 'c0007273',\n",
       " 'c0007282',\n",
       " 'c0007570',\n",
       " 'c0007642',\n",
       " 'c0007642negp',\n",
       " 'c0007762',\n",
       " 'c0007785',\n",
       " 'c0007787',\n",
       " 'c0007789',\n",
       " 'c0008311',\n",
       " 'c0008312',\n",
       " 'c0008313',\n",
       " 'c0008325',\n",
       " 'c0008350',\n",
       " 'c0008370',\n",
       " 'c0008677',\n",
       " 'c0008679',\n",
       " 'c0008767',\n",
       " 'c0009171',\n",
       " 'c0009319',\n",
       " 'c0009324',\n",
       " 'c0009376',\n",
       " 'c0009421',\n",
       " 'c0009443',\n",
       " 'c0009450',\n",
       " 'c0009492',\n",
       " 'c0009566',\n",
       " 'c0009566negp',\n",
       " 'c0009676',\n",
       " 'c0009782',\n",
       " 'c0009814',\n",
       " 'c0009938',\n",
       " 'c0010068',\n",
       " 'c0010068negp',\n",
       " 'c0010346',\n",
       " 'c0010692',\n",
       " 'c0010709',\n",
       " 'c0010957',\n",
       " 'c0011127',\n",
       " 'c0011164',\n",
       " 'c0011168',\n",
       " 'c0011175',\n",
       " 'c0011206',\n",
       " 'c0011253',\n",
       " 'c0011265',\n",
       " 'c0011560',\n",
       " 'c0011570',\n",
       " 'c0011581',\n",
       " 'c0011603',\n",
       " 'c0011620',\n",
       " 'c0011633',\n",
       " 'c0011644',\n",
       " 'c0011813',\n",
       " 'c0011848',\n",
       " 'c0011849',\n",
       " 'c0011854',\n",
       " 'c0011860',\n",
       " 'c0011880',\n",
       " 'c0011881',\n",
       " 'c0011884',\n",
       " 'c0012359',\n",
       " 'c0012546',\n",
       " 'c0012569',\n",
       " 'c0012634',\n",
       " 'c0012634negp',\n",
       " 'c0012691',\n",
       " 'c0012739',\n",
       " 'c0012813',\n",
       " 'c0012818',\n",
       " 'c0012819',\n",
       " 'c0013080',\n",
       " 'c0013142',\n",
       " 'c0013146',\n",
       " 'c0013182',\n",
       " 'c0013182negp',\n",
       " 'c0013238',\n",
       " 'c0013288',\n",
       " 'c0013289',\n",
       " 'c0013295',\n",
       " 'c0013336',\n",
       " 'c0013362',\n",
       " 'c0013405',\n",
       " 'c0013481',\n",
       " 'c0013595',\n",
       " 'c0013604',\n",
       " 'c0013604negp',\n",
       " 'c0013687',\n",
       " 'c0013687negp',\n",
       " 'c0013720',\n",
       " 'c0013922',\n",
       " 'c0013990',\n",
       " 'c0014009',\n",
       " 'c0014038',\n",
       " 'c0014060',\n",
       " 'c0014070',\n",
       " 'c0014118',\n",
       " 'c0014122',\n",
       " 'c0014132',\n",
       " 'c0014335',\n",
       " 'c0014518',\n",
       " 'c0014534',\n",
       " 'c0014544',\n",
       " 'c0014547',\n",
       " 'c0014591',\n",
       " 'c0014661',\n",
       " 'c0014848',\n",
       " 'c0014858',\n",
       " 'c0014860',\n",
       " 'c0014863',\n",
       " 'c0014866',\n",
       " 'c0014867',\n",
       " 'c0015230',\n",
       " 'c0015376',\n",
       " 'c0015459',\n",
       " 'c0015469',\n",
       " 'c0015544',\n",
       " 'c0015802',\n",
       " 'c0015826',\n",
       " 'c0016053',\n",
       " 'c0016057',\n",
       " 'c0016059',\n",
       " 'c0016169',\n",
       " 'c0016522',\n",
       " 'c0016542',\n",
       " 'c0016655',\n",
       " 'c0016658',\n",
       " 'c0016659',\n",
       " 'c0016662',\n",
       " 'c0016664',\n",
       " 'c0017086',\n",
       " 'c0017145',\n",
       " 'c0017150',\n",
       " 'c0017152',\n",
       " 'c0017168',\n",
       " 'c0017181',\n",
       " 'c0017531',\n",
       " 'c0017547',\n",
       " 'c0017589',\n",
       " 'c0017601',\n",
       " 'c0017636',\n",
       " 'c0017658',\n",
       " 'c0017661',\n",
       " 'c0017661negp',\n",
       " 'c0017662',\n",
       " 'c0017665',\n",
       " 'c0017668',\n",
       " 'c0018099',\n",
       " 'c0018099negp',\n",
       " 'c0018133',\n",
       " 'c0018378',\n",
       " 'c0018524',\n",
       " 'c0018621',\n",
       " 'c0018674',\n",
       " 'c0018674negp',\n",
       " 'c0018790',\n",
       " 'c0018794',\n",
       " 'c0018799',\n",
       " 'c0018799negp',\n",
       " 'c0018801',\n",
       " 'c0018802',\n",
       " 'c0018817',\n",
       " 'c0018916',\n",
       " 'c0018944',\n",
       " 'c0018946',\n",
       " 'c0018946negp',\n",
       " 'c0018989',\n",
       " 'c0018995',\n",
       " 'c0019066',\n",
       " 'c0019069',\n",
       " 'c0019080',\n",
       " 'c0019080negp',\n",
       " 'c0019112',\n",
       " 'c0019123',\n",
       " 'c0019151',\n",
       " 'c0019158',\n",
       " 'c0019159',\n",
       " 'c0019163',\n",
       " 'c0019187',\n",
       " 'c0019189',\n",
       " 'c0019191',\n",
       " 'c0019196',\n",
       " 'c0019196negp',\n",
       " 'c0019212',\n",
       " 'c0019270',\n",
       " 'c0019284',\n",
       " 'c0019287',\n",
       " 'c0019288',\n",
       " 'c0019294',\n",
       " 'c0019322',\n",
       " 'c0019326',\n",
       " 'c0019342',\n",
       " 'c0019554',\n",
       " 'c0019557',\n",
       " 'c0019693',\n",
       " 'c0019829',\n",
       " 'c0020162',\n",
       " 'c0020179',\n",
       " 'c0020255',\n",
       " 'c0020295',\n",
       " 'c0020312',\n",
       " 'c0020433',\n",
       " 'c0020437',\n",
       " 'c0020443',\n",
       " 'c0020443negp',\n",
       " 'c0020456',\n",
       " 'c0020473',\n",
       " 'c0020488',\n",
       " 'c0020507',\n",
       " 'c0020510',\n",
       " 'c0020517',\n",
       " 'c0020517negp',\n",
       " 'c0020538',\n",
       " 'c0020538negp',\n",
       " 'c0020540',\n",
       " 'c0020541',\n",
       " 'c0020542',\n",
       " 'c0020550',\n",
       " 'c0020564',\n",
       " 'c0020615',\n",
       " 'c0020617',\n",
       " 'c0020626',\n",
       " 'c0020676',\n",
       " 'c0020963',\n",
       " 'c0021051',\n",
       " 'c0021167',\n",
       " 'c0021167negp',\n",
       " 'c0021308',\n",
       " 'c0021311',\n",
       " 'c0021313',\n",
       " 'c0021390',\n",
       " 'c0021400',\n",
       " 'c0021843',\n",
       " 'c0021943',\n",
       " 'c0021945',\n",
       " 'c0022104',\n",
       " 'c0022116',\n",
       " 'c0022346',\n",
       " 'c0022354',\n",
       " 'c0022408',\n",
       " 'c0022638',\n",
       " 'c0022650',\n",
       " 'c0022658',\n",
       " 'c0022660',\n",
       " 'c0022661',\n",
       " 'c0022665',\n",
       " 'c0022680',\n",
       " 'c0022821',\n",
       " 'c0023211',\n",
       " 'c0023223',\n",
       " 'c0023269',\n",
       " 'c0023418',\n",
       " 'c0023434',\n",
       " 'c0023443',\n",
       " 'c0023448',\n",
       " 'c0023449',\n",
       " 'c0023467',\n",
       " 'c0023470',\n",
       " 'c0023473',\n",
       " 'c0023494',\n",
       " 'c0023518',\n",
       " 'c0023524',\n",
       " 'c0023885',\n",
       " 'c0023890',\n",
       " 'c0023890negp',\n",
       " 'c0023891',\n",
       " 'c0023892',\n",
       " 'c0023895',\n",
       " 'c0023903',\n",
       " 'c0024050',\n",
       " 'c0024115',\n",
       " 'c0024117',\n",
       " 'c0024141',\n",
       " 'c0024143',\n",
       " 'c0024198',\n",
       " 'c0024214',\n",
       " 'c0024215',\n",
       " 'c0024299',\n",
       " 'c0024301',\n",
       " 'c0024302',\n",
       " 'c0024305',\n",
       " 'c0024348',\n",
       " 'c0024437',\n",
       " 'c0024524',\n",
       " 'c0024586',\n",
       " 'c0024588',\n",
       " 'c0024623',\n",
       " 'c0025063',\n",
       " 'c0025202',\n",
       " 'c0025222',\n",
       " 'c0025222negp',\n",
       " 'c0025286',\n",
       " 'c0025289',\n",
       " 'c0025362',\n",
       " 'c0025500',\n",
       " 'c0025568negp',\n",
       " 'c0025570negp',\n",
       " 'c0025874',\n",
       " 'c0026265',\n",
       " 'c0026266',\n",
       " 'c0026267',\n",
       " 'c0026267negp',\n",
       " 'c0026269negp',\n",
       " 'c0026272',\n",
       " 'c0026683',\n",
       " 'c0026684',\n",
       " 'c0026764',\n",
       " 'c0026769',\n",
       " 'c0026771',\n",
       " 'c0026975',\n",
       " 'c0026976',\n",
       " 'c0026986',\n",
       " 'c0026987',\n",
       " 'c0027051',\n",
       " 'c0027059',\n",
       " 'c0027126',\n",
       " 'c0027531',\n",
       " 'c0027543',\n",
       " 'c0027651',\n",
       " 'c0027662',\n",
       " 'c0027667',\n",
       " 'c0027697',\n",
       " 'c0027809',\n",
       " 'c0027947',\n",
       " 'c0028259',\n",
       " 'c0028754',\n",
       " 'c0028756',\n",
       " 'c0028778',\n",
       " 'c0028945',\n",
       " 'c0029184',\n",
       " 'c0029221',\n",
       " 'c0029408',\n",
       " 'c0029421',\n",
       " 'c0029443',\n",
       " 'c0029453',\n",
       " 'c0029456',\n",
       " 'c0029463',\n",
       " 'c0029944',\n",
       " 'c0030283',\n",
       " 'c0030290',\n",
       " 'c0030297',\n",
       " 'c0030299',\n",
       " 'c0030305',\n",
       " 'c0030312',\n",
       " 'c0030486',\n",
       " 'c0030567',\n",
       " 'c0030785',\n",
       " 'c0030807',\n",
       " 'c0030920',\n",
       " 'c0031036',\n",
       " 'c0031039',\n",
       " 'c0031039negp',\n",
       " 'c0031046',\n",
       " 'c0031117',\n",
       " 'c0031154',\n",
       " 'c0031880',\n",
       " 'c0032000',\n",
       " 'c0032227',\n",
       " 'c0032231',\n",
       " 'c0032285',\n",
       " 'c0032290',\n",
       " 'c0032302',\n",
       " 'c0032305',\n",
       " 'c0032326',\n",
       " 'c0032371',\n",
       " 'c0032461',\n",
       " 'c0032584',\n",
       " 'c0032768',\n",
       " 'c0032797',\n",
       " 'c0032897',\n",
       " 'c0032914',\n",
       " 'c0033036',\n",
       " 'c0033141',\n",
       " 'c0033246',\n",
       " 'c0033375',\n",
       " 'c0033377',\n",
       " 'c0033377negp',\n",
       " 'c0033822',\n",
       " 'c0034063',\n",
       " 'c0034065',\n",
       " 'c0034067',\n",
       " 'c0034069',\n",
       " 'c0034186',\n",
       " 'c0034372',\n",
       " 'c0034494',\n",
       " 'c0034888',\n",
       " 'c0035021',\n",
       " 'c0035067',\n",
       " 'c0035078',\n",
       " 'c0035127',\n",
       " 'c0035127negp',\n",
       " 'c0035222',\n",
       " 'c0035258',\n",
       " 'c0035333',\n",
       " 'c0035334',\n",
       " 'c0035357',\n",
       " 'c0035435',\n",
       " 'c0035439',\n",
       " 'c0035455',\n",
       " 'c0035522',\n",
       " 'c0035637',\n",
       " 'c0035854',\n",
       " 'c0035955',\n",
       " 'c0035956',\n",
       " 'c0036091',\n",
       " 'c0036202',\n",
       " 'c0036205',\n",
       " 'c0036323',\n",
       " 'c0036341',\n",
       " 'c0036344',\n",
       " 'c0036429',\n",
       " 'c0036439',\n",
       " 'c0036679',\n",
       " 'c0036690',\n",
       " 'c0036916',\n",
       " 'c0036974',\n",
       " 'c0036980',\n",
       " 'c0036983',\n",
       " 'c0036992',\n",
       " 'c0037052',\n",
       " 'c0037199',\n",
       " 'c0037284',\n",
       " 'c0037293',\n",
       " 'c0037304',\n",
       " 'c0037315',\n",
       " 'c0037926',\n",
       " 'c0037928',\n",
       " 'c0037929',\n",
       " 'c0037930',\n",
       " 'c0037937',\n",
       " 'c0037944',\n",
       " 'c0038000',\n",
       " 'c0038012',\n",
       " 'c0038019',\n",
       " 'c0038220',\n",
       " 'c0038238',\n",
       " 'c0038340',\n",
       " 'c0038354',\n",
       " 'c0038356',\n",
       " 'c0038358',\n",
       " 'c0038358negp',\n",
       " 'c0038436',\n",
       " 'c0038454',\n",
       " 'c0038454negp',\n",
       " 'c0038506',\n",
       " 'c0038525',\n",
       " 'c0038561',\n",
       " 'c0038565',\n",
       " 'c0038663',\n",
       " 'c0038833',\n",
       " 'c0039082',\n",
       " 'c0039082negp',\n",
       " 'c0039240',\n",
       " 'c0039614',\n",
       " 'c0039685',\n",
       " 'c0040034',\n",
       " 'c0040053',\n",
       " 'c0040185',\n",
       " 'c0040213',\n",
       " 'c0040336',\n",
       " 'c0040456',\n",
       " 'c0040583',\n",
       " 'c0040586',\n",
       " 'c0040588',\n",
       " 'c0040715',\n",
       " 'c0040759',\n",
       " 'c0040797',\n",
       " 'c0040961',\n",
       " 'c0040997',\n",
       " 'c0041582',\n",
       " 'c0041582negp',\n",
       " 'c0041755',\n",
       " 'c0041755negp',\n",
       " 'c0041909',\n",
       " 'c0041955',\n",
       " 'c0042024',\n",
       " 'c0042029',\n",
       " 'c0042345',\n",
       " 'c0042345negp',\n",
       " 'c0042373',\n",
       " 'c0042384',\n",
       " 'c0042487',\n",
       " 'c0042510',\n",
       " 'c0042514',\n",
       " 'c0042740',\n",
       " 'c0042749',\n",
       " 'c0042798',\n",
       " 'c0042909',\n",
       " 'c0042961',\n",
       " 'c0043167',\n",
       " 'c0043241',\n",
       " 'c0043246',\n",
       " 'c0043250',\n",
       " 'c0043250negp',\n",
       " 'c0043251',\n",
       " 'c0043251negp',\n",
       " 'c0043252',\n",
       " 'c0043253',\n",
       " 'c0043255',\n",
       " 'c0043540',\n",
       " 'c0078911',\n",
       " 'c0079731',\n",
       " 'c0079734',\n",
       " 'c0079744',\n",
       " 'c0080032',\n",
       " 'c0080178',\n",
       " 'c0080194',\n",
       " 'c0085096',\n",
       " 'c0085119',\n",
       " 'c0085222',\n",
       " 'c0085417',\n",
       " 'c0085581',\n",
       " 'c0085584',\n",
       " 'c0085605',\n",
       " 'c0085649negp',\n",
       " 'c0085669',\n",
       " 'c0085682',\n",
       " 'c0085694',\n",
       " 'c0085762',\n",
       " 'c0085762negp',\n",
       " 'c0086209',\n",
       " 'c0086438',\n",
       " 'c0086447',\n",
       " 'c0086543',\n",
       " 'c0087086',\n",
       " 'c0149516',\n",
       " 'c0149520',\n",
       " 'c0149521',\n",
       " 'c0149531',\n",
       " 'c0149630',\n",
       " 'c0149630negp',\n",
       " 'c0149637',\n",
       " 'c0149645',\n",
       " 'c0149755',\n",
       " 'c0149770',\n",
       " 'c0149801',\n",
       " 'c0149854',\n",
       " 'c0149862',\n",
       " 'c0149871',\n",
       " 'c0149871negp',\n",
       " 'c0149925',\n",
       " 'c0149931',\n",
       " 'c0149931negp',\n",
       " 'c0150055',\n",
       " 'c0151317',\n",
       " 'c0151517',\n",
       " 'c0151546',\n",
       " 'c0151594',\n",
       " 'c0151603',\n",
       " 'c0151699',\n",
       " 'c0151706',\n",
       " 'c0151740',\n",
       " 'c0151824',\n",
       " 'c0152013',\n",
       " 'c0152018',\n",
       " 'c0152020',\n",
       " 'c0152021',\n",
       " 'c0152451',\n",
       " 'c0153676',\n",
       " 'c0153685',\n",
       " 'c0153876',\n",
       " 'c0154298',\n",
       " 'c0155003negp',\n",
       " 'c0155567',\n",
       " 'c0155626',\n",
       " 'c0155668',\n",
       " 'c0155760',\n",
       " 'c0155773',\n",
       " 'c0155842',\n",
       " 'c0158241',\n",
       " 'c0158534',\n",
       " 'c0158570',\n",
       " 'c0158683',\n",
       " 'c0159843',\n",
       " 'c0159877',\n",
       " 'c0160448',\n",
       " 'c0162297',\n",
       " 'c0162316',\n",
       " 'c0162429',\n",
       " 'c0162429negp',\n",
       " 'c0162529',\n",
       " 'c0162557',\n",
       " 'c0162635',\n",
       " 'c0162869',\n",
       " 'c0162870',\n",
       " 'c0162871',\n",
       " 'c0162872',\n",
       " 'c0175677',\n",
       " 'c0175677negp',\n",
       " 'c0178282',\n",
       " 'c0178317',\n",
       " 'c0178324',\n",
       " 'c0178664',\n",
       " 'c0205699',\n",
       " 'c0205748',\n",
       " 'c0205851',\n",
       " 'c0206062',\n",
       " 'c0206138',\n",
       " 'c0206141',\n",
       " 'c0206655',\n",
       " 'c0206674',\n",
       " 'c0206694',\n",
       " 'c0206695',\n",
       " 'c0206698',\n",
       " 'c0206698negp',\n",
       " 'c0206716',\n",
       " 'c0206720',\n",
       " 'c0206754',\n",
       " 'c0220650',\n",
       " 'c0220655',\n",
       " 'c0220656',\n",
       " 'c0220981',\n",
       " 'c0220982',\n",
       " 'c0221103',\n",
       " 'c0221155',\n",
       " 'c0221208',\n",
       " 'c0221209',\n",
       " 'c0221247',\n",
       " 'c0221258',\n",
       " 'c0231176',\n",
       " 'c0231178',\n",
       " 'c0231183',\n",
       " 'c0232197',\n",
       " 'c0232208',\n",
       " 'c0232483',\n",
       " 'c0233407',\n",
       " 'c0233494',\n",
       " 'c0233514',\n",
       " 'c0233660',\n",
       " 'c0233794',\n",
       " 'c0233826',\n",
       " 'c0234469',\n",
       " 'c0234533',\n",
       " 'c0234535',\n",
       " 'c0235325',\n",
       " 'c0235329',\n",
       " 'c0235480',\n",
       " 'c0235782',\n",
       " 'c0235974',\n",
       " 'c0236068',\n",
       " 'c0236663',\n",
       " 'c0237961',\n",
       " 'c0237962',\n",
       " 'c0238096',\n",
       " 'c0238154',\n",
       " 'c0238198',\n",
       " 'c0238199',\n",
       " 'c0238334',\n",
       " 'c0238419',\n",
       " 'c0238436',\n",
       " 'c0238441',\n",
       " 'c0240035',\n",
       " 'c0240059',\n",
       " 'c0240066',\n",
       " 'c0240225',\n",
       " 'c0241424',\n",
       " 'c0241910',\n",
       " 'c0242184',\n",
       " 'c0242231',\n",
       " 'c0242339',\n",
       " 'c0242354',\n",
       " 'c0242363',\n",
       " 'c0242379',\n",
       " 'c0242383',\n",
       " 'c0242528',\n",
       " 'c0242656',\n",
       " 'c0242770',\n",
       " 'c0242966',\n",
       " 'c0243001',\n",
       " 'c0243026',\n",
       " 'c0243066',\n",
       " 'c0259749',\n",
       " 'c0259768',\n",
       " 'c0259795',\n",
       " 'c0262374',\n",
       " 'c0262469',\n",
       " 'c0262537',\n",
       " 'c0262584',\n",
       " 'c0262617',\n",
       " 'c0262627',\n",
       " 'c0262659',\n",
       " 'c0263165',\n",
       " 'c0263313',\n",
       " 'c0263555',\n",
       " 'c0263680',\n",
       " 'c0263853',\n",
       " 'c0263912',\n",
       " 'c0263940',\n",
       " 'c0264316',\n",
       " 'c0264353',\n",
       " 'c0264408',\n",
       " 'c0264488',\n",
       " 'c0264492',\n",
       " 'c0264511',\n",
       " 'c0264550',\n",
       " 'c0264716',\n",
       " 'c0264722',\n",
       " 'c0264733',\n",
       " 'c0264766negp',\n",
       " 'c0264774',\n",
       " 'c0264906',\n",
       " 'c0264907',\n",
       " 'c0264964',\n",
       " 'c0264995',\n",
       " 'c0264998',\n",
       " 'c0265012',\n",
       " 'c0265072',\n",
       " 'c0265890',\n",
       " 'c0265903',\n",
       " 'c0265950',\n",
       " 'c0266270',\n",
       " 'c0266293',\n",
       " 'c0266808',\n",
       " 'c0267080',\n",
       " 'c0267356',\n",
       " 'c0267358',\n",
       " 'c0267489',\n",
       " 'c0267566',\n",
       " 'c0267596',\n",
       " 'c0267596negp',\n",
       " 'c0267672',\n",
       " 'c0267716',\n",
       " 'c0267767',\n",
       " 'c0267797',\n",
       " 'c0267809',\n",
       " 'c0267841',\n",
       " 'c0267844',\n",
       " 'c0267878',\n",
       " 'c0267919',\n",
       " 'c0267941',\n",
       " 'c0267953',\n",
       " 'c0267963',\n",
       " 'c0268748',\n",
       " 'c0270183',\n",
       " 'c0270611',\n",
       " 'c0270612',\n",
       " 'c0270629',\n",
       " 'c0270733',\n",
       " 'c0270814',\n",
       " 'c0270834',\n",
       " 'c0272129',\n",
       " 'c0272457',\n",
       " 'c0272694',\n",
       " 'c0272774',\n",
       " 'c0273112',\n",
       " 'c0273112negp',\n",
       " 'c0274281',\n",
       " 'c0275551',\n",
       " 'c0275613',\n",
       " 'c0275626',\n",
       " 'c0276138',\n",
       " 'c0277554',\n",
       " 'c0277556',\n",
       " 'c0277729',\n",
       " 'c0277785',\n",
       " 'c0277964negp',\n",
       " 'c0278701',\n",
       " 'c0279628',\n",
       " 'c0280302negp',\n",
       " 'c0280785',\n",
       " 'c0281936',\n",
       " 'c0281961',\n",
       " 'c0282612',\n",
       " 'c0302142',\n",
       " 'c0302142negp',\n",
       " 'c0302148',\n",
       " 'c0302592',\n",
       " 'c0311262',\n",
       " 'c0311273',\n",
       " 'c0332448',\n",
       " 'c0332568',\n",
       " 'c0332666',\n",
       " 'c0332679',\n",
       " 'c0332713',\n",
       " 'c0332759',\n",
       " 'c0332798',\n",
       " 'c0332853',\n",
       " 'c0332875',\n",
       " 'c0332885',\n",
       " 'c0332886',\n",
       " 'c0333056',\n",
       " 'c0333062',\n",
       " 'c0333124',\n",
       " 'c0333133',\n",
       " 'c0333138',\n",
       " 'c0333157',\n",
       " 'c0333161',\n",
       " 'c0333169',\n",
       " 'c0333204',\n",
       " 'c0333222',\n",
       " 'c0333253',\n",
       " 'c0333276',\n",
       " 'c0333278',\n",
       " 'c0333291',\n",
       " 'c0333292',\n",
       " 'c0333297',\n",
       " 'c0333307',\n",
       " 'c0333497',\n",
       " 'c0333536',\n",
       " 'c0333548',\n",
       " 'c0333557',\n",
       " 'c0333606',\n",
       " 'c0333710',\n",
       " 'c0334044',\n",
       " 'c0334108',\n",
       " 'c0334277',\n",
       " 'c0334533',\n",
       " 'c0334576',\n",
       " 'c0334583',\n",
       " 'c0334590',\n",
       " 'c0334634',\n",
       " 'c0337196',\n",
       " 'c0337228',\n",
       " 'c0337230',\n",
       " 'c0338078',\n",
       " 'c0338106',\n",
       " 'c0338471',\n",
       " 'c0340013',\n",
       " 'c0340229',\n",
       " 'c0340231',\n",
       " 'c0340288',\n",
       " 'c0340289',\n",
       " 'c0340305',\n",
       " 'c0340324',\n",
       " 'c0340629',\n",
       " 'c0340630',\n",
       " 'c0340643',\n",
       " 'c0340647',\n",
       " 'c0340657',\n",
       " 'c0340861',\n",
       " 'c0341129',\n",
       " 'c0341318',\n",
       " 'c0341377',\n",
       " 'c0341503',\n",
       " 'c0341539',\n",
       " 'c0341697',\n",
       " 'c0342257',\n",
       " 'c0342257negp',\n",
       " 'c0342569',\n",
       " 'c0343024',\n",
       " 'c0343401',\n",
       " 'c0344911',\n",
       " 'c0345135',\n",
       " 'c0345832',\n",
       " 'c0345905',\n",
       " 'c0346255',\n",
       " 'c0346429',\n",
       " 'c0346647',\n",
       " 'c0346991',\n",
       " 'c0347266',\n",
       " 'c0347630',\n",
       " 'c0347633',\n",
       " 'c0347646',\n",
       " 'c0347766',\n",
       " 'c0347812',\n",
       " 'c0347950',\n",
       " 'c0348801',\n",
       " 'c0348916negp',\n",
       " 'c0349566',\n",
       " 'c0349782',\n",
       " 'c0376288',\n",
       " 'c0376358',\n",
       " 'c0392525',\n",
       " 'c0398353',\n",
       " 'c0398623',\n",
       " 'c0399526',\n",
       " 'c0399586',\n",
       " 'c0400827',\n",
       " 'c0400839',\n",
       " 'c0400979',\n",
       " 'c0401151',\n",
       " 'c0403419',\n",
       " 'c0403447',\n",
       " 'c0403597',\n",
       " 'c0406810',\n",
       " 'c0409974',\n",
       " 'c0410000',\n",
       " 'c0410648',\n",
       " 'c0413120',\n",
       " 'c0413252',\n",
       " 'c0417023',\n",
       " 'c0417031',\n",
       " 'c0423772',\n",
       " 'c0428974',\n",
       " 'c0428977',\n",
       " 'c0431112',\n",
       " 'c0434034',\n",
       " 'c0435630',\n",
       " 'c0439857',\n",
       " ...]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_cui.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf_cui = vect_cui.transform(df_train.CUIS.values)\n",
    "X_valid_tf_cui = vect_cui.transform(df_valid.CUIS.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = []\n",
    "AUC = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for BoW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression(C = 0.0001, penalty = 'l2', random_state = 42)\n",
    "clf.fit(X_train_text_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6997000305341851"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_preds = clf.predict_proba(X_valid_text_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_valid_preds)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"LR on BoW\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for BoW + BoC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression(C = 0.0001, penalty = 'l2', random_state = 42)\n",
    "clf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6996818392324153"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_preds = clf.predict_proba(X_valid_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_valid_preds)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"LR on BoW & BoC\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes (NB) for BoW + BoC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_Array = X_train_tf.todense()\n",
    "X_valid_Array = X_valid_tf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.548621524356283"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "y_valid_preds = gnb.fit(X_train_Array, y_train).predict_proba(X_valid_Array) \n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_valid_preds[:,1])\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"NB on BoW & BoC\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with TF_IDF for BoW + BoC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression(C = 0.0001, penalty = 'l2', random_state = 42)\n",
    "clf.fit(X_train_tf_IDF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6585868384741611"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_preds_TF_IDF = clf.predict_proba(X_valid_tf_IDF)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_valid_preds_TF_IDF)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"LR on TF-IDF of BoW & BoC\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression on BoC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_cui=LogisticRegression(C = 0.0001, penalty = 'l2', random_state = 42)\n",
    "clf_cui.fit(X_train_tf_cui, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5716469520558891"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_preds_cui = clf_cui.predict_proba(X_valid_tf_cui)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_valid_preds_cui)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"LR on BoC\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of CUIs alone does not yield a good result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Networks on BoW and BoC:\n",
    "#### Here I am using a simple one layer neural network to see if I can get a better result than LR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = to_categorical(y_train)\n",
    "y_valid_binary = to_categorical(y_valid)\n",
    "X_train_Array = X_train_tf.todense()\n",
    "X_valid_Array = X_valid_tf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim = X_train_tf.shape[1] , activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(optimizer=Adam(0.000001), loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4784 samples, validate on 10223 samples\n",
      "Epoch 1/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1934 - acc: 0.9304 - val_loss: 0.8700 - val_acc: 0.6806\n",
      "Epoch 2/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1959 - acc: 0.9254 - val_loss: 0.8661 - val_acc: 0.6821\n",
      "Epoch 3/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1942 - acc: 0.9266 - val_loss: 0.8742 - val_acc: 0.6790\n",
      "Epoch 4/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1953 - acc: 0.9258 - val_loss: 0.8811 - val_acc: 0.6778\n",
      "Epoch 5/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1947 - acc: 0.9260 - val_loss: 0.8978 - val_acc: 0.6725\n",
      "Epoch 6/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1863 - acc: 0.9308 - val_loss: 0.8657 - val_acc: 0.6828\n",
      "Epoch 7/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1874 - acc: 0.9360 - val_loss: 0.8593 - val_acc: 0.6858\n",
      "Epoch 8/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1931 - acc: 0.9298 - val_loss: 0.8913 - val_acc: 0.6761\n",
      "Epoch 9/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1881 - acc: 0.9323 - val_loss: 0.9005 - val_acc: 0.6732\n",
      "Epoch 10/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1859 - acc: 0.9360 - val_loss: 0.8901 - val_acc: 0.6770\n",
      "Epoch 11/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1845 - acc: 0.9321 - val_loss: 0.8919 - val_acc: 0.6770\n",
      "Epoch 12/50\n",
      "4784/4784 [==============================] - 7s 2ms/step - loss: 0.1864 - acc: 0.9352 - val_loss: 0.8952 - val_acc: 0.6766\n",
      "Epoch 13/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1838 - acc: 0.9348 - val_loss: 0.8974 - val_acc: 0.6765\n",
      "Epoch 14/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1839 - acc: 0.9337 - val_loss: 0.9036 - val_acc: 0.6752\n",
      "Epoch 15/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1890 - acc: 0.9243 - val_loss: 0.9012 - val_acc: 0.6761\n",
      "Epoch 16/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1892 - acc: 0.9281 - val_loss: 0.8919 - val_acc: 0.6796\n",
      "Epoch 17/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1807 - acc: 0.9350 - val_loss: 0.9026 - val_acc: 0.6763\n",
      "Epoch 18/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1849 - acc: 0.9321 - val_loss: 0.9212 - val_acc: 0.6705\n",
      "Epoch 19/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1863 - acc: 0.9308 - val_loss: 0.8986 - val_acc: 0.6785\n",
      "Epoch 20/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1778 - acc: 0.9327 - val_loss: 0.9226 - val_acc: 0.6702\n",
      "Epoch 21/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1791 - acc: 0.9358 - val_loss: 0.9094 - val_acc: 0.6748\n",
      "Epoch 22/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1820 - acc: 0.9348 - val_loss: 0.9310 - val_acc: 0.6681\n",
      "Epoch 23/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1819 - acc: 0.9348 - val_loss: 0.8878 - val_acc: 0.6820\n",
      "Epoch 24/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1737 - acc: 0.9385 - val_loss: 0.9210 - val_acc: 0.6726\n",
      "Epoch 25/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1767 - acc: 0.9394 - val_loss: 0.9188 - val_acc: 0.6734\n",
      "Epoch 26/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1797 - acc: 0.9352 - val_loss: 0.9121 - val_acc: 0.6760\n",
      "Epoch 27/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1670 - acc: 0.9371 - val_loss: 0.9237 - val_acc: 0.6726\n",
      "Epoch 28/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1768 - acc: 0.9367 - val_loss: 0.9474 - val_acc: 0.6662\n",
      "Epoch 29/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1771 - acc: 0.9377 - val_loss: 0.9107 - val_acc: 0.6762\n",
      "Epoch 30/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1656 - acc: 0.9452 - val_loss: 0.9198 - val_acc: 0.6740\n",
      "Epoch 31/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1687 - acc: 0.9375 - val_loss: 0.9303 - val_acc: 0.6723\n",
      "Epoch 32/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1740 - acc: 0.9367 - val_loss: 0.9224 - val_acc: 0.6749\n",
      "Epoch 33/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1651 - acc: 0.9427 - val_loss: 0.9306 - val_acc: 0.6730\n",
      "Epoch 34/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1728 - acc: 0.9369 - val_loss: 0.9306 - val_acc: 0.6727\n",
      "Epoch 35/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1695 - acc: 0.9431 - val_loss: 0.9319 - val_acc: 0.6733\n",
      "Epoch 36/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1701 - acc: 0.9373 - val_loss: 0.9400 - val_acc: 0.6712\n",
      "Epoch 37/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1644 - acc: 0.9446 - val_loss: 0.9292 - val_acc: 0.6736\n",
      "Epoch 38/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1686 - acc: 0.9377 - val_loss: 0.9455 - val_acc: 0.6706\n",
      "Epoch 39/50\n",
      "4784/4784 [==============================] - 7s 2ms/step - loss: 0.1677 - acc: 0.9371 - val_loss: 0.9356 - val_acc: 0.6725\n",
      "Epoch 40/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1699 - acc: 0.9388 - val_loss: 0.9235 - val_acc: 0.6765\n",
      "Epoch 41/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1702 - acc: 0.9377 - val_loss: 0.9278 - val_acc: 0.6756\n",
      "Epoch 42/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1648 - acc: 0.9431 - val_loss: 0.9339 - val_acc: 0.6735\n",
      "Epoch 43/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1591 - acc: 0.9429 - val_loss: 0.9362 - val_acc: 0.6742\n",
      "Epoch 44/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1661 - acc: 0.9398 - val_loss: 0.9433 - val_acc: 0.6728\n",
      "Epoch 45/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1547 - acc: 0.9444 - val_loss: 0.9409 - val_acc: 0.6740\n",
      "Epoch 46/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1619 - acc: 0.9377 - val_loss: 0.9463 - val_acc: 0.6731\n",
      "Epoch 47/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1594 - acc: 0.9406 - val_loss: 0.9505 - val_acc: 0.6724\n",
      "Epoch 48/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1619 - acc: 0.9423 - val_loss: 0.9334 - val_acc: 0.6774\n",
      "Epoch 49/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1625 - acc: 0.9417 - val_loss: 0.9642 - val_acc: 0.6684\n",
      "Epoch 50/50\n",
      "4784/4784 [==============================] - 8s 2ms/step - loss: 0.1616 - acc: 0.9419 - val_loss: 0.9578 - val_acc: 0.6703\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efee36321d0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_Array, y_train_binary, epochs=500, batch_size=128, validation_data=(X_valid_Array, y_valid_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7088444749106246"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_valid_Array)\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_pred[:,1])\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('NN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"NN on BoW & BoC\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using up to 3 n-grams for best models (LR and NN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=50000, min_df=1,\n",
       "        ngram_range=(1, 3), preprocessor=None,\n",
       "        stop_words=['the', 'and', 'to', 'of', 'was', 'with', 'a', 'on', 'in', 'for', 'name', 'is', 'patient', 's', 'he', 'at', 'as', 'or', 'one', 'she', 'his', 'her', 'am', 'were', 'you', 'pt', 'pm', 'by', 'be', 'had', 'your', 'this', 'date', 'from', 'there', 'an', 'that', 'p', 'are', 'have', 'has', 'h', 'but', 'o', 'namepattern', 'which', 'every', 'also'],\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features = 50000,  \n",
    "                       stop_words = my_stop_words,\n",
    "                       ngram_range= (1,3))\n",
    "vect.fit(df_train.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tf = vect.transform(df_train.TEXT_CUIS.values)\n",
    "X_valid_tf = vect.transform(df_valid.TEXT_CUIS.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with ngrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=42,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression(C = 0.0001, penalty = 'l2', random_state = 42)\n",
    "clf.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7061031987449021"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_preds = clf.predict_proba(X_valid_tf)[:, 1]\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_valid_preds)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"LR on BoW & BoC & up to 3grams\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NN with ngrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = to_categorical(y_train)\n",
    "y_valid_binary = to_categorical(y_valid)\n",
    "X_train_Array = X_train_tf.todense()\n",
    "X_valid_Array = X_valid_tf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim = X_train_tf.shape[1] , activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(optimizer=Adam(0.000001), loss= 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4784 samples, validate on 10223 samples\n",
      "Epoch 1/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1589 - acc: 0.9500 - val_loss: 0.8753 - val_acc: 0.6788\n",
      "Epoch 2/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1547 - acc: 0.9557 - val_loss: 0.8618 - val_acc: 0.6830\n",
      "Epoch 3/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1546 - acc: 0.9569 - val_loss: 0.8601 - val_acc: 0.6838\n",
      "Epoch 4/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1521 - acc: 0.9557 - val_loss: 0.8769 - val_acc: 0.6801\n",
      "Epoch 5/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1464 - acc: 0.9615 - val_loss: 0.8616 - val_acc: 0.6853\n",
      "Epoch 6/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1506 - acc: 0.9546 - val_loss: 0.8810 - val_acc: 0.6797\n",
      "Epoch 7/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1476 - acc: 0.9601 - val_loss: 0.8768 - val_acc: 0.6820\n",
      "Epoch 8/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1465 - acc: 0.9548 - val_loss: 0.8740 - val_acc: 0.6836\n",
      "Epoch 9/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1445 - acc: 0.9578 - val_loss: 0.8756 - val_acc: 0.6833\n",
      "Epoch 10/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1427 - acc: 0.9599 - val_loss: 0.8682 - val_acc: 0.6864\n",
      "Epoch 11/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1443 - acc: 0.9561 - val_loss: 0.8928 - val_acc: 0.6807\n",
      "Epoch 12/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1432 - acc: 0.9588 - val_loss: 0.8853 - val_acc: 0.6827\n",
      "Epoch 13/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1384 - acc: 0.9643 - val_loss: 0.8980 - val_acc: 0.6800\n",
      "Epoch 14/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1374 - acc: 0.9640 - val_loss: 0.8847 - val_acc: 0.6852\n",
      "Epoch 15/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1332 - acc: 0.9615 - val_loss: 0.8972 - val_acc: 0.6825\n",
      "Epoch 16/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1369 - acc: 0.9592 - val_loss: 0.9068 - val_acc: 0.6800\n",
      "Epoch 17/20\n",
      "4784/4784 [==============================] - 13s 3ms/step - loss: 0.1346 - acc: 0.9622 - val_loss: 0.9143 - val_acc: 0.6779\n",
      "Epoch 18/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1322 - acc: 0.9630 - val_loss: 0.9082 - val_acc: 0.6802\n",
      "Epoch 19/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1306 - acc: 0.9599 - val_loss: 0.8891 - val_acc: 0.6878\n",
      "Epoch 20/20\n",
      "4784/4784 [==============================] - 14s 3ms/step - loss: 0.1322 - acc: 0.9638 - val_loss: 0.9219 - val_acc: 0.6773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc9ace3a20>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_Array, y_train_binary, epochs=20, batch_size=128, validation_data=(X_valid_Array, y_valid_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7156490418454344"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_proba(X_valid_Array)\n",
    "fpr, tpr, _ = metrics.roc_curve(np.array(y_valid), y_pred[:,1])\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('NN_model_ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model.append(\"NN on BoW & BoC & up to 3grams\")\n",
    "AUC.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "Results = pd.DataFrame({'Model': Model, 'AUC': AUC})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing results of different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR on BoW</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR on BoW &amp; BoC</td>\n",
       "      <td>0.699682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NB on BoW &amp; BoC</td>\n",
       "      <td>0.548622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR on TF-IDF of BoW &amp; BoC</td>\n",
       "      <td>0.658587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR on BoC</td>\n",
       "      <td>0.571647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NN on BoW &amp; BoC</td>\n",
       "      <td>0.708844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR on BoW &amp; BoC &amp; up to 3grams</td>\n",
       "      <td>0.706103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NN on BoW &amp; BoC &amp; up to 3grams</td>\n",
       "      <td>0.715649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Model       AUC\n",
       "0                       LR on BoW  0.699700\n",
       "1                 LR on BoW & BoC  0.699682\n",
       "2                 NB on BoW & BoC  0.548622\n",
       "3       LR on TF-IDF of BoW & BoC  0.658587\n",
       "4                       LR on BoC  0.571647\n",
       "5                 NN on BoW & BoC  0.708844\n",
       "6  LR on BoW & BoC & up to 3grams  0.706103\n",
       "7  NN on BoW & BoC & up to 3grams  0.715649"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results.to_pickle('AUC_Models_BoW.pkl')\n",
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "   * Adding bag of polarized CUIs to the analysis does not improve the results. It could be caused by the high correlation between text and CUIs. Also, I have realized that cTAKES sometimes cannot catch polarization and negation. It is also reported by my classmates.\n",
    "    \n",
    "   * Bag of CUIs alone does not yield good results.\n",
    "   \n",
    "   * Naive Bayes which is well-known for being fast and having high performance doesn't do well in this case. I have also tried Random Forest but it doesn't do well.\n",
    "   \n",
    "   * Adding up to 3-grams slightly improves the result.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
